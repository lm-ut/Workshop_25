{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINUX users can open the terminal window with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ctrl+Alt+T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login into rocket with your account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh your_account_id@rocket.hpc.ut.ee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and Setting up a conda environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps available at Anaconda website: https://docs.anaconda.com/miniconda/install/#quick-command-line-install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p ~/miniconda3\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n",
    "bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n",
    "rm ~/miniconda3/miniconda.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Check you bashrc file (more ~/.bashrc) to see whether conda edited last section of the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exit and re-enter terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy the environment and create it in your directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda env create -f /gpfs/helios/projects/echo_workshops/project.1.tk/conda_env/echo_workshop.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate echo_workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good practices when starting a new project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good practice to keep your directory clean and well-organized. \n",
    "\n",
    "For example, given that today we will work on the non imputed dataset we can create right away the directory 'non_imputed' with the command `mkdir` (mkdir = make directory), where we will store the dataset and run the analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir non_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To move into the newly create directory you can use the `cd` command (cd = change directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd non_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There, you can create right away another directory: `Exploring_PCA`, where you can store the dataset, and run the analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir Exploring_PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dataset\n",
    "The vcf is readily available at /gpfs/helios/projects/echo_workshops/project.1.tk/data/PopStructureFiles/non_imputed.vcf. Be sure that you are currently in your 'non_imputed/dataset' folder and copy the file in your directory is this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /gpfs/helios/projects/echo_workshops/project.1.tk/data/PopStructureFiles/non_imputed.vcf ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are working on a remote server, where multiple users work with different software needs. Managing many softwares and many versions is complex, and can cause dependency issues. \n",
    "\n",
    "Rather than having installed and readily available all softwares we use **modules**. Modules allow to manage and load software environments dynamically, ensuring that the correct versions of software and their dependencies are used without conflicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before **loading** a specific module, we need to search for it, to know whether it is available and under what name. \n",
    "\n",
    "`module spider` will provide a list of all available softwares and their version under the searched name. \n",
    "\n",
    "`module spider plink`\n",
    "\n",
    "`module load` is used to activate a specific software environment by loading the desired module. \n",
    "\n",
    "`module load plink/1.9-beta6.27`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset seen through PLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module spider plink\n",
    "module load plink/1.9-beta6.27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert vcf to plink format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plink --vcf non_imputed.vcf --keep-allele-order --make-bed --out non_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While converting PLINK informs us about:\n",
    " * Number of SNPS (variants)\n",
    " * Number of individuals (people) and number of male/females\n",
    " * Genotyping rate"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n",
    "(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
    "Logging to non_imputed_set.log.\n",
    "Options in effect:\n",
    "  --keep-allele-order\n",
    "  --make-bed\n",
    "  --out non_imputed\n",
    "  --vcf non_imputed.vcf\n",
    "\n",
    "128131 MB RAM detected; reserving 64065 MB for main workspace.\n",
    "--vcf: non_imputed-temporary.bed + non_imputed-temporary.bim +\n",
    "non_imputed-temporary.fam written.\n",
    "301636 variants loaded from .bim file.\n",
    "421 people (0 males, 0 females, 421 ambiguous) loaded from .fam.\n",
    "Ambiguous sex IDs written to non_imputed.nosex .\n",
    "Using 1 thread (no multithreaded calculations invoked).\n",
    "Before main variant filters, 421 founders and 0 nonfounders present.\n",
    "Calculating allele frequencies... done.\n",
    "Total genotyping rate is 0.828553.\n",
    "301636 variants and 421 people pass filters and QC.\n",
    "Note: No phenotypes present.\n",
    "--make-bed to non_imputed.bed + non_imputed.bim + non_imputed.fam ... done.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the number of SNPs and samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily count the number of SNPs by counting the lines in the bim file with bash `wc -l`.\n",
    "\n",
    "`wc` = word count \\\n",
    "`-l` = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc -l non_imputed.bim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can count the number of Samples by counting the lines in the fam file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc -l non_imputed.fam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the FID are available, we can estimate the number of samples per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '{print $1}' non_imputed.fam | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allele Frequencies\n",
    "The dataset can be characterized by many rare or many common variants. The allele frequencies will impact the study, and the kind of analyses we can carry on the dataset. For an insight of the allele frequencies in out dataset we can use the `--freq` options in PLINK, which writes a minor allele frequency report to an output **.frq** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plink --bfile non_imputed --freq --out allele_freq_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the first few lines with the command `head`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head allele_freq_report.frq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file has 6 columns:\n",
    "\n",
    "* CHR\tChromosome number\n",
    "* SNP\tVariant identifier\n",
    "* A1\tAllele 1 (usually minor)\n",
    "* A2\tAllele 2 (usually major)\n",
    "* MAF\tAllele 1 frequency, stands for Minor Allele Frequency\n",
    "* NCHROBS\tNumber of allele observations (number of samples*2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many alleles have a MAF lower than 0.05?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '$5 < 0.05 {print $5}' allele_freq_report.frq | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove them with the plink option `--maf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plink --bfile non_imputed --maf 0.05 --make-bed --out non_imputed_maf05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the level of missingness in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plink --bfile non_imputed --missing --out missingness_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLINK will create two output, with thr prefix 'missingness_check'. \n",
    "* missingness_check.imiss\n",
    "* missingness_check.lmiss\n",
    "\n",
    "We can check the first ten lines of files contain with the command `head`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missingness_check.imiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head missingness_check.imiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i**miss stantds for individuals missingness, the file summarizes the missing genotype rates per individual. \n",
    "* FID contains the sample cluster/family name\n",
    "* IID contains the sample individual ID\n",
    "* MISS_PHENO indicates whether the phenotype information is missing (Y/N)\n",
    "* N_MISS\tNumber of missing genotype call(s)\n",
    "* N_GENO\tNumber of potentially valid call(s)\n",
    "* F_MISS\tMissing call rate, proportion of N_MISS/N_GENO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the 20 samples with:\n",
    "1) highest missingness\n",
    "2) lowest missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort -k6,6 -n missingness_check.imiss | tail -n 20\n",
    "sort -k6,6 -nr missingness_check.imiss | tail -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing samples with high missingness\n",
    "For filtering out low-quality samples we can use the PLINK option `--mind N`. With this option we will remove all samples with a missingess equal or higher than N. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plink --bfile non_imputed --mind 0.9 --make-bed --out non_imputed_mind9 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use N = 0.9, how many samples will be removed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missingness_check.lmiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head missingness_check.lmiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**l**miss stands for locus missingness, it summarizes the missing genotype rates per SNP (locus).\n",
    "* CHR column inform on the chromosome number.\n",
    "* SNP is SNP ID.\n",
    "* N_MISS Number of missing genotypes for this SNP across all individuals.\n",
    "* N_GENO Total number of genotypes for this SNP across all individuals.\n",
    "* F_MISS Proportion of missing genotypes for this SNP (N_MISS / N_GENO)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing SNPs with high missingness\n",
    "For filtering out low-quality SNPs we can use the PLINK option `--geno N`. With this option we will remove all variants with a missingess equal or higher than N. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plink --bfile non_imputed --geno 0.9 --make-bed --out non_imputed_geno9 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linkage Disequilibrium\n",
    "\n",
    "Linkage disequilibrium refers to the non-random association of alleles at different loci. When two SNPs are in LD, they tend to be inherited together more often than would be expected by chance. \\\n",
    "When not accounting for LD, we mistakenly interpret an association between two variants as causal, when in reality the association could be due to their co-inheritance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove sites in LD, we can use PLINK option `--indep-pairwise`. It takes 3 parameters: window size, step size, r^2 threshold.\n",
    "\n",
    "1) We select a window size in variant count (i.e. 100, will select a window with 100 SNPs, first parameter)\n",
    "2) We remove all SNPs with a r^2 equal or higher than our threshold (i.e. 0.1, third parameter), measure the association between two SNPs\n",
    "3) PLINK will shift the window a number of variants, and perform step 1 and 2 (i.e. 10, will shift the window 10 SNPs, second parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--indep-pairwise <window size>['kb'] <step size (variant ct)> <r^2 threshold>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plink --bfile non_imputed --indep-pairphase 1000 100 0.5 --out pruning_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command will output two files: pruning_report.prune.in and pruning_report.prune.out\n",
    "* prune.in, variants that passed the pruning parameters\n",
    "* prune.out, variants that did NOT pass the pruning parameters\n",
    "\n",
    "We can now subset the dataset based on the pruning_report files, by running **one** of these two line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plink --bfile non_imputed --extract pruning_report.prune.in --make-bed --out non_imputed_pruned \n",
    "plink --bfile non_imputed --exclude pruning_report.prune.out --make-bed --out non_imputed_pruned "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the genetic variability with PCA\n",
    "\n",
    "We are providing you a script that will perform the following:\n",
    "1) Convert vcf to plink format\n",
    "2) Apply maf and LD filters\n",
    "3) Convert plink file to eigenstrat format\n",
    "4) Run smartpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python /gpfs/helios/projects/echo_workshops/project.1.tk/scripts/VCF2smartpca.py\n",
    "--name my_pca_script \n",
    "--input_file non_imputed \n",
    "--maf 0.05 \n",
    "--pruning '1000 100 0.5' \n",
    "--pca_project YES \n",
    "--pca_controls Albanian.HO,Belarusian.HO,Bulgarian.HO,Croatian.HO,Cypriot.HO,Czech.HO,English.HO,Estonian.HO,Finnish.HO,French.HO,Greek.HO,Hungarian.HO,Icelandic.HO,Italian.North.HO,Lithuanian.HO,Maltese.HO,Norwegian.HO,Orcadian.HO,Romanian.HO,Russian.HO,Scottish.HO,Sicilian.HO,Spanish.HO,Spanish.North.HO,Ukrainian.HO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script will create a \"my_pca_script.sh\" bash file with all command lines needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more my_pca_script.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbatch my_pca_script.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the script is done running, you will find in your directory two files:\n",
    "* **pca.evec**, containing the coordinates of each individual along each principal component (eigenvectors).\n",
    "* **eval**, containing the eigenvalues, indicating how much variance each principal component explains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the variance explained for each PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '{sum += $1} END {print sum}' non_imputed_maf0.05_pruned.eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say it returns 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat non_imputed_maf0.05_pruned.eval | while read line; \n",
    "do explained_variance=$(echo \"scale=4; $line / 108 * 100\" | bc); \n",
    "echo \"Explained variance: $explained_variance%\" >> explained_variance_output.txt; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can plot the PCA using PCA_plot.R script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate echo_workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscript /gpfs/helios/projects/echo_workshops/project.1.tk/scripts/PCA_plot.R non_imputed_maf0.05_pruned.pca.evec output.pdf \n",
    "# or\n",
    "Rscript /gpfs/helios/projects/echo_workshops/project.1.tk/scripts/PCA_plot.R non_imputed_maf0.05_pruned.pca.evec output_focus.pdf --focus FranceLIA.Anc,\n",
    "KoksijdeEMA.Anc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ggrepel error?\n",
    "\n",
    "Try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "R version 4.2.0 (2022-04-22) -- \"Vigorous Calisthenics\"\n",
    "Copyright (C) 2022 The R Foundation for Statistical Computing\n",
    "Platform: x86_64-conda-linux-gnu (64-bit)\n",
    "\n",
    "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
    "You are welcome to redistribute it under certain conditions.\n",
    "Type 'license()' or 'licence()' for distribution details.\n",
    "\n",
    "R is a collaborative project with many contributors.\n",
    "Type 'contributors()' for more information and\n",
    "'citation()' on how to cite R or R packages in publications.\n",
    "\n",
    "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
    "'help.start()' for an HTML browser interface to help.\n",
    "Type 'q()' to quit R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"ggrepel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And follow the instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"dplyr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And follow the instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"optparse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And follow the instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if python issues are thrown: try pip install packaging==21.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A few notes on the smartpca par file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can find additional info: https://github.com/chrchang/eigensoft/blob/master/POPGEN/README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the par file (therefore, the options) we used for our PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypename: {output_name}.geno\n",
    "snpname: {output_name}.snp\n",
    "indivname: {output_name}.ind\n",
    "evecoutname: {output_name}.pca.evec\n",
    "evaloutname: {output_name}.eval\n",
    "numoutevec: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- numoutvec: number of eigenvectors to output. It's the number of PCs. While the default is 10, we used only 4.\n",
    "\n",
    "##### Projection \n",
    "- lsqproject:  YES PCA projections is carried out by solving least squares equations rather than an orthogonal projection step.  This is approriate if PCs are calculated using samples with little missing data but it is desired to project samples with much missing data onto the top PCs.\n",
    "- poplistname:   If wishing to infer eigenvectors using only individuals from a subset of populations, and then project individuals from all populations onto those eigenvectors, this input file contains a list of population names, one population name per line, which will be used to infer eigenvectors. It is assumed that the population of each individual is specified in the indiv file. Default is to use individuals from all populations.\n",
    "\n",
    "##### Manipulating the normalization\n",
    "- altnormstyle: Affects very subtle details in normalization formula. Default is YES (normalization formulas of Patterson et al. 2006). To match EIGENSTRAT (normalization formulas of Price et al. 2006), set to NO.\n",
    "\n",
    "##### Removing Outliers\n",
    "- numoutlieriter: maximum number of outlier removal iterations. Default is 5.To turn off outlier removal, set this parameter to 0.\n",
    "- numoutlierevec: number of principal components along which to remove outliers during each outlier removal iteration.  Default is 10.\n",
    "- outliersigmathresh: number of standard deviations which an individual must exceed, along one of the top (numoutlierevec) principal components, in order for that individual to be removed as an outlier.  Default is 6.0.\n",
    "\n",
    "##### Shrink Mode\n",
    "- shrinkmode: YES  (default NO) \n",
    "A problem with smartpca is that samples used to calculate the PC axes \n",
    "\"stretch\" the axes.  So that 2 populations in fact genetically identical \n",
    "(2 independent samples from the same underlying population) will appear different \n",
    "if one is used to compute axes, and one not.  shrinkmode: YES is an attempt \n",
    "to solve this problem.  \n",
    "*** warning *** shrinkmode is slow and will greatly increase the runtime. \n",
    "(NEW) New version:  newshrink:  YES technical variation of shrinkmode,  should be (slightly) \n",
    "- autoshrink: YES  (default NO)  A new method (Liu, Dobriban, Singer: https://arxiv.org/pdf/1611.05550.pdf) of eigenvalue shrinkage. This costs little in CPU, but the results seem slightly worse than shrinkmode: YES.  \n",
    "\n",
    "##### Fst Estimation\n",
    "- fstonly: If set to YES, then skip PCA and just calculate FST values. The default value for this parameter is NO."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
